"""
Streamlit Web UI for MCP Client
ç”¨æ¥æµ‹è¯•çš„ï¼Œä¸æ˜¯æœ€ç»ˆç‰ˆæœ¬
"""

import json
import requests
import streamlit as st
from typing import List, Dict, Any
from datetime import datetime

from mylib.config import ConfigLoader


class MCPClientWeb:
    """Web ç‰ˆæœ¬çš„ MCP å®¢æˆ·ç«¯"""
    
    def __init__(self):
        self.config = ConfigLoader()
        host = str(self.config.LLM_CONFIG.MCP_SERVER_HOST)
        port = str(self.config.LLM_CONFIG.MCP_SERVER_PORT)
        self.mcp_server_url = f"http://{host}:{port}"
        self.api_key = getattr(self.config.LLM_CONFIG, "DEEPSEEK_API_KEY", "")
        self.base_url = "https://api.deepseek.com/v1"
        self.available_tools = self._load_tools()
    
    def _load_tools(self) -> List[Dict]:
        """ä»MCPæœåŠ¡å™¨åŠ è½½å¯ç”¨å·¥å…·"""
        try:
            response = requests.get(f"{self.mcp_server_url}/tools", timeout=5)
            if response.status_code == 200:
                return response.json()["tools"]
            else:
                return []
        except Exception as e:
            st.error(f"è¿æ¥MCPæœåŠ¡å™¨é”™è¯¯: {e}")
            return []
    
    def call_tool(self, tool_name: str, arguments: Dict) -> Any:
        """è°ƒç”¨MCPå·¥å…·"""
        try:
            response = requests.post(
                f"{self.mcp_server_url}/tools/{tool_name}/call",
                json=arguments,
                timeout=30
            )
            if response.status_code == 200:
                result = response.json()
                return result
            else:
                return {"error": f"HTTPé”™è¯¯: {response.status_code}"}
        except Exception as e:
            return {"error": f"è°ƒç”¨å·¥å…·é”™è¯¯: {str(e)}"}
    
    def chat_with_llm(self, message: str, conversation_history: List[Dict], is_tool_result: bool = False) -> str:
        """ä¸LLMå¯¹è¯, æ”¯æŒå·¥å…·è°ƒç”¨"""
        headers = {
            "Content-Type": "application/json",
            "Authorization": f"Bearer {self.api_key}"
        }
        
        system_prompt = f"""ä½ æ˜¯ä¸€ä¸ªAIåŠ©æ‰‹ï¼Œå¯ä»¥è°ƒç”¨å„ç§å·¥å…·æ¥å¸®åŠ©ç”¨æˆ·å®Œæˆä»»åŠ¡ã€‚

å¯ç”¨å·¥å…·:
{json.dumps(self.available_tools, indent=2, ensure_ascii=False)}

å·¥å…·è°ƒç”¨è§„åˆ™:
1. å½“éœ€è¦è°ƒç”¨å·¥å…·æ—¶ï¼Œè¯·æŒ‰ç…§ä»¥ä¸‹æ ¼å¼å“åº”ï¼š
TOOL_CALL: {{
    "tool_calls": [
        {{
            "name": "tool_name",
            "arguments": {{
                "param1": "value1",
                "param2": "value2"
            }}
        }}
    ]
}}

2. ä½ å¯ä»¥è¿ç»­å¤šæ¬¡è°ƒç”¨å·¥å…·æ¥å®Œæˆå¤æ‚ä»»åŠ¡
3. æ¯æ¬¡å·¥å…·è°ƒç”¨åï¼Œæˆ‘ä¼šè¿”å›ç»“æœç»™ä½ ï¼Œä½ å¯ä»¥åŸºäºç»“æœå†³å®šï¼š
    - ç»§ç»­è°ƒç”¨å…¶ä»–å·¥å…·ï¼ˆè¿”å›æ–°çš„ TOOL_CALLï¼‰
    - å·²è·å¾—è¶³å¤Ÿä¿¡æ¯ï¼Œç»™å‡ºæœ€ç»ˆç­”æ¡ˆï¼ˆè¿”å› TOOL_CALL_ENDï¼‰

4. å½“ä½ è®¤ä¸ºå·²ç»æ”¶é›†åˆ°è¶³å¤Ÿä¿¡æ¯å¯ä»¥å›ç­”ç”¨æˆ·é—®é¢˜æ—¶ï¼Œå¿…é¡»åœ¨å›å¤å¼€å¤´æ·»åŠ æ ‡è®°ï¼š
TOOL_CALL_END

ç„¶åç»™å‡ºä½ çš„æœ€ç»ˆç­”æ¡ˆã€‚

æ³¨æ„ï¼šä¸è¦åœ¨å·¥å…·è°ƒç”¨é˜¶æ®µå°è¯•å›ç­”é—®é¢˜ï¼Œå…ˆå®Œæˆæ‰€æœ‰å¿…è¦çš„å·¥å…·è°ƒç”¨ï¼Œæœ€åç»Ÿä¸€å›ç­”ã€‚"""

        if not conversation_history:
            messages = [
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": message}
            ]
        else:
            messages = [{"role": "system", "content": system_prompt}] + conversation_history
            if is_tool_result:
                messages.append({"role": "user", "content": f"å·¥å…·è°ƒç”¨ç»“æœ:\n{message}\n\nè¯·åŸºäºç»“æœå†³å®šä¸‹ä¸€æ­¥æ“ä½œã€‚"})
            else:
                messages.append({"role": "user", "content": message})
        
        payload = {
            "model": "deepseek-chat",
            "messages": messages,
            "temperature": 0.7,
            "max_tokens": 2000,
            "stream": False
        }
        
        try:
            response = requests.post(
                f"{self.base_url}/chat/completions",
                headers=headers,
                json=payload,
                timeout=30
            )
            
            if response.status_code == 200:
                result = response.json()
                assistant_message = result["choices"][0]["message"]["content"]
                return assistant_message
            else:
                return f"APIè°ƒç”¨é”™è¯¯: {response.status_code} - {response.text}"
                
        except Exception as e:
            return f"LLMè°ƒç”¨é”™è¯¯: {str(e)}"
    
    def process_user_request(self, user_input: str, log_history: List[Dict], update_callback=None) -> tuple[str, List[Dict]]:
        """å¤„ç†ç”¨æˆ·è¯·æ±‚ï¼Œæ”¯æŒè¿ç»­å·¥å…·è°ƒç”¨
        
        Args:
            user_input: ç”¨æˆ·è¾“å…¥
            log_history: æ—¥å¿—å†å²åˆ—è¡¨ï¼ˆä¼šè¢«ä¿®æ”¹ï¼‰
            update_callback: æ›´æ–°å›è°ƒå‡½æ•°ï¼Œæ¯æ¬¡æ·»åŠ æ—¥å¿—åè°ƒç”¨ä»¥åˆ·æ–°ç•Œé¢
            
        Returns:
            (æœ€ç»ˆç­”æ¡ˆ, å¯¹è¯å†å²)
        """
        conversation_history = []
        
        # é¦–æ¬¡ LLM è°ƒç”¨
        timestamp = datetime.now().strftime('%H:%M:%S')
        log_history.append({
            "type": "info",
            "content": "å‘é€ç”¨æˆ·è¯·æ±‚åˆ° LLM...",
            "timestamp": timestamp
        })
        if update_callback:
            update_callback()
        
        llm_response = self.chat_with_llm(user_input, conversation_history, is_tool_result=False)
        conversation_history.append({"role": "user", "content": user_input})
        conversation_history.append({"role": "assistant", "content": llm_response})
        
        log_history.append({
            "type": "llm_response",
            "content": llm_response,
            "round": 1,
            "timestamp": datetime.now().strftime('%H:%M:%S')
        })
        if update_callback:
            update_callback()
        
        # å·¥å…·è°ƒç”¨å¾ªç¯è®¡æ•°
        tool_call_round = 0
        max_rounds = 10
        
        while tool_call_round < max_rounds:
            if "TOOL_CALL_END" in llm_response:
                log_history.append({
                    "type": "success",
                    "content": "å·¥å…·è°ƒç”¨ç»“æŸï¼Œè¿”å›æœ€ç»ˆç­”æ¡ˆ",
                    "timestamp": datetime.now().strftime('%H:%M:%S')
                })
                if update_callback:
                    update_callback()
                final_answer = llm_response.replace("TOOL_CALL_END", "").strip()
                return final_answer, conversation_history
            
            if "TOOL_CALL:" not in llm_response:
                return llm_response, conversation_history
            
            try:
                tool_call_round += 1
                
                log_history.append({
                    "type": "tool_call_start",
                    "round": tool_call_round,
                    "timestamp": datetime.now().strftime('%H:%M:%S')
                })
                if update_callback:
                    update_callback()
                
                tool_call_json = llm_response.split("TOOL_CALL:")[1].strip()
                json_start = tool_call_json.find('{')
                json_end = tool_call_json.rfind('}') + 1
                if json_start >= 0 and json_end > json_start:
                    tool_call_json = tool_call_json[json_start:json_end]
                
                tool_call_data = json.loads(tool_call_json)
                
                tool_results = []
                for idx, tool_call in enumerate(tool_call_data.get("tool_calls", []), 1):
                    tool_name = tool_call.get("name")
                    tool_args = tool_call.get("arguments", {})
                    
                    result = self.call_tool(tool_name, tool_args)
                    
                    log_history.append({
                        "type": "tool_execution",
                        "tool_name": tool_name,
                        "arguments": tool_args,
                        "result": result,
                        "idx": idx,
                        "timestamp": datetime.now().strftime('%H:%M:%S')
                    })
                    if update_callback:
                        update_callback()
                    
                    tool_results.append({
                        "tool": tool_name,
                        "arguments": tool_args,
                        "result": result
                    })
                
                tool_results_message = json.dumps(tool_results, indent=2, ensure_ascii=False)
                conversation_history.append({"role": "user", "content": f"å·¥å…·è°ƒç”¨ç»“æœ:\n{tool_results_message}"})
                
                log_history.append({
                    "type": "info",
                    "content": "å‘é€å·¥å…·ç»“æœåˆ° LLM...",
                    "timestamp": datetime.now().strftime('%H:%M:%S')
                })
                if update_callback:
                    update_callback()
                
                llm_response = self.chat_with_llm(tool_results_message, conversation_history, is_tool_result=True)
                conversation_history.append({"role": "assistant", "content": llm_response})
                
                log_history.append({
                    "type": "llm_response",
                    "content": llm_response,
                    "round": tool_call_round + 1,
                    "timestamp": datetime.now().strftime('%H:%M:%S')
                })
                if update_callback:
                    update_callback()
                
            except json.JSONDecodeError as e:
                error_msg = f"å·¥å…·è°ƒç”¨ JSON è§£æé”™è¯¯: {e}"
                log_history.append({
                    "type": "error",
                    "content": error_msg,
                    "timestamp": datetime.now().strftime('%H:%M:%S')
                })
                if update_callback:
                    update_callback()
                return error_msg, conversation_history
            except Exception as e:
                error_msg = f"å·¥å…·è°ƒç”¨è¿‡ç¨‹é”™è¯¯: {e}"
                log_history.append({
                    "type": "error",
                    "content": error_msg,
                    "timestamp": datetime.now().strftime('%H:%M:%S')
                })
                if update_callback:
                    update_callback()
                return error_msg, conversation_history
        
        warning_msg = f"âš ï¸ å·¥å…·è°ƒç”¨è¶…è¿‡æœ€å¤§è½®æ¬¡é™åˆ¶ ({max_rounds})"
        log_history.append({
            "type": "error",
            "content": warning_msg,
            "timestamp": datetime.now().strftime('%H:%M:%S')
        })
        if update_callback:
            update_callback()
        return llm_response, conversation_history


def main():
    """Streamlit ä¸»åº”ç”¨"""
    
    st.set_page_config(
        page_title="MCP Client - Web UI",
        page_icon="ğŸ¤–",
        layout="wide",
        initial_sidebar_state="collapsed"
    )
    
    st.markdown("""
        <style>
        .user-message {
            background-color: #E8D5F2;
            padding: 15px;
            border-radius: 10px;
            margin: 10px 0;
        }
        .assistant-message {
            background-color: #D5F2F2;
            padding: 15px;
            border-radius: 10px;
            margin: 10px 0;
        }
        .message-header {
            font-weight: bold;
            margin-bottom: 8px;
        }
        .stTextInput > div > div > input {
            font-size: 16px;
        }
        .stTextArea > div > div > textarea {
            font-size: 16px;
        }
        .log-container {
            max-height: 70vh;
            overflow-y: auto;
        }
        </style>
    """, unsafe_allow_html=True)
    
    st.title("ğŸ¤– MCP Client - Web UI")
    st.caption("åŸºäº Model Context Protocol çš„æ™ºèƒ½åŠ©æ‰‹")
    
    if "client" not in st.session_state:
        st.session_state.client = MCPClientWeb()
    
    if "chat_history" not in st.session_state:
        st.session_state.chat_history = []
    
    if "processing" not in st.session_state:
        st.session_state.processing = False
    
    if "log_history" not in st.session_state:
        st.session_state.log_history = []
    
    with st.sidebar:
        st.header("ğŸ“š å¯ç”¨å·¥å…·")
        if st.session_state.client.available_tools:
            for tool in st.session_state.client.available_tools:
                with st.expander(f"ğŸ”§ {tool['name']}"):
                    st.write(tool['description'])
                    if 'parameters' in tool:
                        st.json(tool['parameters'])
        else:
            st.warning("âš ï¸ æ— æ³•è¿æ¥åˆ° MCP æœåŠ¡å™¨")
            st.info("è¯·ç¡®ä¿ MCP Server å·²å¯åŠ¨ï¼š\n```bash\nuv run python ./main.py server\n```")
        
        if st.button("ğŸ”„ åˆ·æ–°å·¥å…·åˆ—è¡¨"):
            st.session_state.client.available_tools = st.session_state.client._load_tools()
            st.rerun()
        
        if st.button("ğŸ—‘ï¸ æ¸…ç©ºå¯¹è¯å†å²"):
            st.session_state.chat_history = []
            st.session_state.log_history = []
            st.rerun()
    
    col1, col2 = st.columns([3, 2])
    
    with col1:
        st.header("ğŸ’¬ å¯¹è¯")
        
        chat_container = st.container()
        with chat_container:
            if not st.session_state.chat_history:
                st.info("ğŸ‘‹ å–µ~æ¬¢è¿å›å®¶æï¼è¿™é‡Œæ˜¯æ‹æ‹ï¼Œä¸€ä¸ªä¼šé­”æ³•çš„å°çŒ«å¨˜åŠ©æ‰‹")
            else:
                for msg in st.session_state.chat_history:
                    if msg["role"] == "user":
                        st.markdown(f"""
                        <div class="user-message">
                            <div class="message-header">ğŸ™‹ Sakurine</div>
                            <div>{msg["content"]}</div>
                        </div>
                        """, unsafe_allow_html=True)
                    elif msg["role"] == "assistant":
                        st.markdown(f"""
                        <div class="assistant-message">
                            <div class="message-header">ğŸ¤– æ‹</div>
                            <div>{msg["content"]}</div>
                        </div>
                        """, unsafe_allow_html=True)
        
        st.markdown("---")
        with st.form(key="chat_form", clear_on_submit=True):
            user_input = st.text_area(
                "ğŸ’­ è¾“å…¥ä½ çš„é—®é¢˜...",
                placeholder="ä¾‹å¦‚ï¼šè¯»å– /tmp/test.txt çš„å†…å®¹",
                disabled=st.session_state.processing,
                key="user_input",
                height=100
            )
            submit_button = st.form_submit_button(
                "ğŸ“¤ å‘é€",
                use_container_width=True,
                disabled=st.session_state.processing
            )
        
        if submit_button and user_input:
            st.session_state.processing = True
            st.rerun()
    
    with col2:
        st.header("ğŸ“Š æ‰§è¡Œæ—¥å¿—")
        
        progress_placeholder = st.empty()
        
        log_display = st.container()
        
        def render_logs():
            with log_display:
                if not st.session_state.log_history:
                    st.info("ğŸ” ç­‰å¾…ç”¨æˆ·è¾“å…¥...")
                else:
                    for log_entry in st.session_state.log_history:
                        log_type = log_entry.get("type")
                        content = log_entry.get("content")
                        timestamp = log_entry.get("timestamp", "")
                        
                        if log_type == "llm_response":
                            round_num = log_entry.get("round", 1)
                            with st.expander(f"ğŸ“ LLM å“åº” #{round_num} ({timestamp})", expanded=False):
                                st.text(content[:500] + ("..." if len(content) > 500 else ""))
                        
                        elif log_type == "tool_call_start":
                            round_num = log_entry.get("round")
                            st.markdown(f"### ğŸ”§ å·¥å…·è°ƒç”¨è½®æ¬¡ #{round_num}")
                            st.caption(f"â° {timestamp}")
                        
                        elif log_type == "tool_execution":
                            tool_name = log_entry.get("tool_name")
                            tool_args = log_entry.get("arguments")
                            result = log_entry.get("result")
                            idx = log_entry.get("idx", 1)
                            
                            with st.expander(f"ğŸ› ï¸ å·¥å…· #{idx}: {tool_name}", expanded=False):
                                st.json({"arguments": tool_args})
                                result_str = json.dumps(result, ensure_ascii=False)
                                if len(result_str) > 500:
                                    st.text_area("ç»“æœ", result_str[:500] + "...", height=100, key=f"result_{timestamp}_{idx}")
                                else:
                                    st.json(result)
                        
                        elif log_type == "info":
                            st.info(f"â° {timestamp} - {content}")
                        
                        elif log_type == "success":
                            st.success(f"âœ… {timestamp} - {content}")
                        
                        elif log_type == "error":
                            st.error(content)
        
        render_logs()
    
    if st.session_state.processing:
        user_input = st.session_state.get("user_input", "")
        
        if user_input:
            st.session_state.chat_history.append({
                "role": "user",
                "content": user_input
            })
            
            log_placeholder = st.empty()
            progress_bar = progress_placeholder.progress(0)
            status_text = st.empty()
            
            def update_ui():
                """å®æ—¶æ›´æ–° UI"""
                with log_placeholder.container():
                    for log_entry in st.session_state.log_history:
                        log_type = log_entry.get("type")
                        content = log_entry.get("content")
                        timestamp = log_entry.get("timestamp", "")
                        
                        if log_type == "llm_response":
                            round_num = log_entry.get("round", 1)
                            with st.expander(f"ğŸ“ LLM å“åº” #{round_num} ({timestamp})", expanded=False):
                                st.text(content[:500] + ("..." if len(content) > 500 else ""))
                        
                        elif log_type == "tool_call_start":
                            round_num = log_entry.get("round")
                            st.markdown(f"### ğŸ”§ å·¥å…·è°ƒç”¨è½®æ¬¡ #{round_num}")
                            st.caption(f"â° {timestamp}")
                        
                        elif log_type == "tool_execution":
                            tool_name = log_entry.get("tool_name")
                            tool_args = log_entry.get("arguments")
                            result = log_entry.get("result")
                            idx = log_entry.get("idx", 1)
                            
                            with st.expander(f"ğŸ› ï¸ å·¥å…· #{idx}: {tool_name}", expanded=False):
                                st.json({"arguments": tool_args})
                                result_str = json.dumps(result, ensure_ascii=False)
                                if len(result_str) > 500:
                                    st.text_area("ç»“æœ", result_str[:500] + "...", height=100, key=f"result_{timestamp}_{idx}_{len(st.session_state.log_history)}")
                                else:
                                    st.json(result)
                        
                        elif log_type == "info":
                            st.info(f"â° {timestamp} - {content}")
                        
                        elif log_type == "success":
                            st.success(f"âœ… {timestamp} - {content}")
                        
                        elif log_type == "error":
                            st.error(content)
                
                total_steps = 10
                current_step = len(st.session_state.log_history)
                progress = min(current_step / total_steps, 0.99)
                progress_bar.progress(progress)
                
                if st.session_state.log_history:
                    last_log = st.session_state.log_history[-1]
                    if last_log["type"] == "info":
                        status_text.info(f"ğŸ”„ {last_log['content']}")
                    elif last_log["type"] == "success":
                        status_text.success(f"âœ… {last_log['content']}")
                        progress_bar.progress(1.0)
            
            response, _ = st.session_state.client.process_user_request(
                user_input,
                st.session_state.log_history,
                update_callback=update_ui
            )
            
            progress_bar.progress(1.0)
            status_text.success("âœ… å¤„ç†å®Œæˆï¼")
            
            st.session_state.chat_history.append({
                "role": "assistant",
                "content": response
            })
        
        st.session_state.processing = False
        st.rerun()


if __name__ == "__main__":
    main()
